{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huybui/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing, metrics\n",
    "import gc\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(data):\n",
    "    \n",
    "    x_train = data[data['date'] <= '2016-03-27']\n",
    "    y_train = x_train['demand']\n",
    "    x_val = data[(data['date'] > '2016-03-27') & (data['date'] <= '2016-04-24')]\n",
    "    y_val = x_val['demand']\n",
    "    test = data[(data['date'] > '2016-04-24')]\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    # define random hyperparammeters\n",
    "    params = {    \n",
    "        'min_child_weight': 0.03454472573214212,\n",
    "        'feature_fraction': 0.3797454081646243,\n",
    "        'bagging_fraction': 0.4181193142567742,\n",
    "        'min_data_in_leaf': 106,\n",
    "        'objective': 'regression',\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.006883242363721497,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_seed\": 11,\n",
    "        \"metric\": 'rmse',\n",
    "        \"verbosity\": -1,\n",
    "        'reg_alpha': 0.3899927210061127,\n",
    "        'reg_lambda': 0.6485237330340494,\n",
    "        'random_state': 47\n",
    "    }\n",
    "\n",
    "    train_set = lgb.Dataset(x_train[features], y_train)\n",
    "    val_set = lgb.Dataset(x_val[features], y_val)\n",
    "    \n",
    "    del x_train, y_train\n",
    "\n",
    "    model = lgb.train(params, train_set, valid_sets = [train_set, val_set], verbose_eval = 100)\n",
    "    val_pred = model.predict(x_val[features])\n",
    "    val_score = np.sqrt(metrics.mean_squared_error(val_pred, y_val))\n",
    "    print(f'Our val rmse score is {val_score}')\n",
    "    y_pred = model.predict(test[features])\n",
    "    test['demand'] = y_pred\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test, submission):\n",
    "    predictions = test[['id', 'date', 'demand']]\n",
    "    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on = 'id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    final.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../ExportData/clean_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to evaluate with the last 28 days\n",
    "x_train = data[data['date'] <= '2016-03-27']\n",
    "y_train = x_train['demand']\n",
    "x_val = data[(data['date'] > '2016-03-27') & (data['date'] <= '2016-04-24')]\n",
    "y_val = x_val['demand']\n",
    "test = data[(data['date'] > '2016-04-24')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'year', 'month', 'week', 'day', 'dayofweek', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', \n",
    "            'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_t28', 'lag_t29', 'lag_t30', 'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t30', 'rolling_mean_t90', \n",
    "            'rolling_mean_t180', 'rolling_std_t30', 'price_change_t1', 'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t30', 'rolling_skew_t30', 'rolling_kurt_t30']\n",
    "\n",
    "train_set = lgb.Dataset(x_train[features], y_train)\n",
    "val_set = lgb.Dataset(x_val[features], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {    \n",
    "        'min_child_weight': 0.03454472573214212,\n",
    "        'feature_fraction': 0.3797454081646243,\n",
    "        'bagging_fraction': 0.4181193142567742,\n",
    "        'min_data_in_leaf': 106,\n",
    "        'objective': 'regression',\n",
    "        'max_depth': -1,\n",
    "        'learning_rate': 0.006883242363721497,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"bagging_seed\": 11,\n",
    "        \"metric\": 'rmse',\n",
    "        \"verbosity\": -1,\n",
    "        'reg_alpha': 0.3899927210061127,\n",
    "        'reg_lambda': 0.6485237330340494,\n",
    "        'random_state': 47\n",
    "    }\n",
    "\n",
    "\n",
    "model = lgb.train(params, train_set, valid_sets = [train_set, val_set], verbose_eval = 100)\n",
    "val_pred = model.predict(x_val[features])\n",
    "val_score = np.sqrt(metrics.mean_squared_error(val_pred, y_val))\n",
    "print(f'Our val rmse score is {val_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
